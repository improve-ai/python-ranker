{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propensity model results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic variants creation\n",
    "\n",
    "In order to create synthetic variants package [coolname](https://pypi.org/project/coolname/) was used. Package is able to generate 'meaningful' names which can be 2 - 5 words long. In order to make sure names would get non-zero features after feature encoding step the following strings must have been present in the generated name:\n",
    "\n",
    "```python\n",
    " DES_WORDS = \\\n",
    "        ['simple', 'free', 'love', 'embrace', 'moment', 'gratitude', 'grateful',\n",
    "         'fixed', 'live', 'now', 'hard', 'together', 'kind']\n",
    "\n",
    "```\n",
    "\n",
    "In order to make sure encoding creates more than one feature each synthetic varaint looked as follows:\n",
    "\n",
    "```python\n",
    "\n",
    "randomly_generated_name = 'grateful whale of much wisdom'\n",
    "\n",
    "variant = {\n",
    "    'text': randomly_generated_name,\n",
    "    'chars': len(curr_text), \n",
    "    'words': len(randomly_generated_name.split(' '))}\n",
    "\n",
    "```\n",
    "\n",
    "300 of such dictionaries were generated as synthetic variants\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propensities \n",
    "\n",
    "3 distributions were used to 'hardcode' variants' propensities:\n",
    " - uniform distribution (each variant had a chance of being chosen equal to `p = 1/N` where N is number of variants\n",
    " - normal with mean = 150 and SD = 30 (10000 samples were used to aproximate this distribution)\n",
    " - 1-param [Weibull](https://numpy.org/doc/stable/reference/random/generated/numpy.random.weibull.html) with a = 10 (10000 samples were used to aproximate this distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"./plots/props.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f677c417da0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./plots/props.html', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cases / propensity model data creation ways:\n",
    "\n",
    " - #1 - for each decision all variants but chosen one get 0 and a chosen one gets 1. This approach creates N rows for each decision / sample (where `N = number of variants`):\n",
    "\n",
    " \n",
    " | variant          | is chosen | variant's weight |\n",
    " |------------------|-----------|----------------|\n",
    " | randomly selected best variant  | 1 | 1 |\n",
    " | 1st of remaining variants  | 0 | 1 |\n",
    " | 2nd of remaining variants  | 0 | 1 |\n",
    " | ...  | ... | ... |\n",
    " | last of remaining variants  | 0 | 1 |\n",
    " \n",
    " \n",
    " \n",
    " - #2 - chosen variant is flagged as 1 and gets weight of 1. one of not chosen variants is selected randomly and flagged as 0 with `weight =  N - 1` where `N = number of vairants`. This approach creates 2 rows per decision / sample:\n",
    " \n",
    " \n",
    "  | variant          | is chosen | variant's weight |\n",
    " |------------------|-----------|----------------|\n",
    " | randomly selected best variant  | 1 | 1 |\n",
    " | one of remaining variants  | 0 | N - 1 |\n",
    " \n",
    " \n",
    "  - #3 All variants have `is chosen` initially set to 0. When decision / sampling is made chosen variant is appended to variants' list with `is chosen` set to 1 (this makes chosen variant occur twice per decision / sample). To account for this effect propensity calculated by model must be corrected by: p<sub>corrected</sub> = p<sub>model</sub> / (1 - p<sub>model</sub>). This approach creates N + 1 rows per decisions / sample (where N is a number of variants)\n",
    " \n",
    "  \n",
    " \n",
    " | variant          | is chosen | variant's weight |\n",
    " |------------------|-----------|----------------|\n",
    " | randomly selected best variant  | 1 | 1 |\n",
    " | randomly selected best variant  | 0 | 1 |\n",
    " | 1st of remaining variants  | 0 | 1 |\n",
    " | 2nd of remaining variants  | 0 | 1 |\n",
    " | ...  | ... | ... |\n",
    " | last of remaining variants  | 0 | 1 |\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Vanilla XGBoost classifier was used as a propensity estimator. Variables obtained with feature encoding were used as predictor variables and `is chosen` flag was used a target variable. Feature encoding was performed with 'hash table' of the most recent messages model - [link to model](https://improve-v5-resources-prod-models-117097735164.s3-us-west-2.amazonaws.com/models/mindful/latest/improve-messages-2.0.xgb.gz)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of propensity models\n",
    "\n",
    "\n",
    "Case #2 has data for 5k+ decision / samples because data sets had signifficantly less rows and fit in my pc's RAM while #1 and #3 didn't (e.g. #2 had 10k rows for 5k decisions while #1 generated 1500000 rows for 300 variants and 5k decisions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of sum of obtained propensities for approaches #1, #2 and #3 and different distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"./plots/model_propensity_sum-uni.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f677c417470>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./plots/model_propensity_sum-uni.html', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"./plots/model_propensity_sum-norm_m150_sd30.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f677c4452e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./plots/model_propensity_sum-norm_m150_sd30.html', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"./plots/model_propensity_sum-weib_rl5_a10.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f677c445550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./plots/model_propensity_sum-weib_rl5_a10.html', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Symmetric Mean Absolute Percentage Error (SMAPE) of obtained propensities vs hardcoded propensities for approaches #1, #2 and #3 and different distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"./plots/propensity_smape-uni.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f677c445908>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./plots/propensity_smape-uni.html', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"./plots/propensity_smape-norm_m150_sd30.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f677c445f28>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./plots/propensity_smape-norm_m150_sd30.html', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"./plots/propensity_smape-weib_rl5_a10.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f677c3d6518>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./plots/propensity_smape-weib_rl5_a10.html', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of total computation time (4 cores) for approaches #1, #2 and #3 and different distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"./plots/total_duration_mins-uni.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f677c3d6320>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./plots/total_duration_mins-uni.html', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"./plots/total_duration_mins-norm_m150_sd30.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f677c3d67f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./plots/total_duration_mins-norm_m150_sd30.html', width=1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"./plots/total_duration_mins-weib_rl5_a10.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f677c3d6ac8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='./plots/total_duration_mins-weib_rl5_a10.html', width=1000, height=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
